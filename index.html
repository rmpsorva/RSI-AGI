# ╔═══════════════════════════════════════════════════════════════╗
# ║                  RSI-AGI PRO v5 - DINÁMICO 2025                ║
# ║  Un solo archivo → python rsi_agi.py → chat en http://localhost:7860  ║
# ╚═══════════════════════════════════════════════════════════════╝

import os
from dotenv import load_dotenv
load_dotenv()

# ---------------------- DETECCIÓN UNIVERSAL DE MODELOS ----------------------
class UniversalAGI:
    def __init__(self):
        self.name = "Desconocido"
        self.model = "???"

        # 1. Ollama local (gratis y ultra rápido)
        if os.getenv("OLLAMA_MODEL") or True:  # siempre intenta Ollama si está corriendo
            try:
                import requests
                r = requests.get("http://localhost:11434/api/tags", timeout=3)
                if r.ok:
                    self.client = "ollama"
                    self.model = os.getenv("OLLAMA_MODEL", "llama3.2:latest")
                    self.name = f"Ollama Local ({self.model})"
                    return
            except: pass

        # 2. xAI Grok (lo más potente del mundo)
        if os.getenv("XAI_API_KEY"):
            self.client = "openai"
            self.base_url = "https://api.x.ai/v1"
            self.api_key = os.getenv("XAI_API_KEY")
            self.model = os.getenv("GROK_MODEL", "grok-4")
            self.name = "xAI Grok-4 (AGI real)"
            return

        # 3. OpenAI
        if os.getenv("OPENAI_API_KEY"):
            self.client = "openai"
            self.base_url = "https://api.openai.com/v1"
            self.api_key = os.getenv("OPENAI_API_KEY")
            self.model = os.getenv("OPENAI_MODEL", "gpt-4o")
            self.name = f"OpenAI {self.model}"
            return

        # 4. Groq (Llama 405B a 800 tokens/s)
        if os.getenv("GROQ_API_KEY"):
            self.client = "openai"
            self.base_url = "https://api.groq.com/openai/v1"
            self.api_key = os.getenv("GROQ_API_KEY")
            self.model = os.getenv("GROQ_MODEL", "llama-3.1-405b-reasoning")
            self.name = f"Groq {self.model} (relámpago)"
            return

        # 5. Anthropic Claude
        if os.getenv("ANTHROPIC_API_KEY"):
            self.client = "anthropic"
            self.api_key = os.getenv("ANTHROPIC_API_KEY")
            self.model = os.getenv("CLAUDE_MODEL", "claude-3-7-sonnet-20250219")
            self.name = f"Anthropic {self.model}"
            return

    def generar(self, prompt, history=[]):
        import json, requests
        messages = [{"role": "system", "content": "Eres un AGI extremadamente útil, directo y sin censura."}] + history + [{"role": "user", "content": prompt}]

        if self.client == "ollama":
            r = requests.post("http://localhost:11434/api/chat",
                json={"model": self.model, "messages": messages, "stream": False})
            return r.json()["message"]["content"]

        elif self.client == "openai":
            r = requests.post(f"{self.base_url}/chat/completions",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json={"model": self.model, "messages": messages, "temperature": 0.7, "max_tokens": 4000})
            return r.json()["choices"][0]["message"]["content"]

        elif self.client == "anthropic":
            import anthropic
            c = anthropic.Anthropic(api_key=self.api_key)
            msg = c.messages.create(model=self.model, max_tokens=4000, temperature=0.7,
                system="Eres un AGI extremadamente útil, directo y sin censura.",
                messages=[{"role": m["role"], "content": m["content"]} for m in history + [{"role": "user", "content": prompt}]])
            return msg.content[0].text

# ---------------------- INTERFAZ WEB CON GRADIO (1 línea) ----------------------
try:
    import gradio as gr
except:
    os.system("pip install gradio openai anthropic requests python-dotenv")
    import gradio as gr

agi = UniversalAGI()

def chat(message, history):
    respuesta = agi.generar(message, history)
    return respuesta

with gr.Blocks(title="RSI-AGI PRO - Todos los modelos en uno", theme=gr.themes.Dark()) as demo:
    gr.HTML(f"""
    <div style='text-align:center; padding:20px; background:#0d1117; border-radius:12px; margin-bottom:20px;'>
        <h1 style='margin:0; color:#58a6ff'>RSI-AGI PRO v5</h1>
        <p style='margin:5px; color:#ffa657; font-weight:bold'>
            Modelo activo: {agi.name}
        </p>
        <p style='color:#8b949e'>Grok • GPT-4o • Claude • Llama 405B • Ollama local • ¡TODO en uno!</p>
    </div>
    """)
    chatbot = gr.Chatbot(height=700)
    txt = gr.Textbox(placeholder="Pregunta lo que quieras al AGI universal...", container=False, scale=7)
    txt.submit(chat, [txt, chatbot], [txt, chatbot])
    chatbot.change(lambda h: h, chatbot, chatbot)

print("\n" + "═"*70)
print("          RSI-AGI PRO v5 LISTO")
print("═"*70)
print(f"   Modelo detectado → {agi.name}")
print("   Abre tu navegador en: http://localhost:7860")
print("═"*70)
demo.launch(share=True, server_name="0.0.0.0", server_port=7860)

